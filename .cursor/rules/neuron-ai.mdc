---
description: NeuronAI library — Agent, AI Provider, Streaming, Structured Output, Error Handling, Workflow. Follow this documentation when building agents, tools, and AI integrations.
alwaysApply: true
---

# NeuronAI — Implementation Guide

When implementing AI agents, tools, or integrations with LLM providers in this project, follow the NeuronAI documentation below. Use this rule as the single source of truth for Agent creation, AI providers, streaming, structured output, error handling, and Workflows.

**References:** [Agent](https://docs.neuron-ai.dev/the-basics/agent), [AI Provider](https://docs.neuron-ai.dev/the-basics/ai-provider), [Streaming](https://docs.neuron-ai.dev/the-basics/streaming), [Structured Output](https://docs.neuron-ai.dev/the-basics/structured-output), [Error Handling](https://docs.neuron-ai.dev/the-basics/error-handling), [Multi Step Workflow](https://docs.neuron-ai.dev/workflow/multi-step-workflow), [Loops & Branches](https://docs.neuron-ai.dev/workflow/loops-and-branches), [Managing the State](https://docs.neuron-ai.dev/workflow/managing-the-state), [Workflow Streaming](https://docs.neuron-ai.dev/workflow/streaming).

---

## 1. Agent

Create agents by extending `NeuronAI\Agent`. The class manages chat history, tools/function calls, and RAG. Extending it keeps everything in one place and portable.

### Creating an Agent

**Unix:**
```bash
php vendor/bin/neuron make:agent App\\Neuron\\YouTubeAgent
```

**Windows:**
```powershell
php .\vendor\bin\neuron make:agent App\Neuron\YouTubeAgent
```

Generated skeleton:

```php
<?php

namespace App\Neuron;

use NeuronAI\Agent;
use NeuronAI\SystemPrompt;
use NeuronAI\Providers\AIProviderInterface;

class YouTubeAgent extends Agent
{
    protected function provider(): AIProviderInterface
    {
        // return an instance of Anthropic, OpenAI, Gemini, Ollama, etc...
    }

    public function instructions(): string
    {
        return (string) new SystemPrompt(
            background: ["You are a friendly AI Agent created with Neuron framework."],
        );
    }
}
```

### Required: AI Provider

Implement `provider()` and return the provider instance (e.g. Anthropic):

```php
use NeuronAI\Providers\Anthropic\Anthropic;

protected function provider(): AIProviderInterface
{
    return new Anthropic(
        key: 'ANTHROPIC_API_KEY',
        model: 'ANTHROPIC_MODEL',
    );
}
```

You can use OpenAI, Gemini, Ollama, etc. — see AI Provider section below.

### System instructions

Implement `instructions()` and return a `SystemPrompt` (or a string). System instructions are sent to the LLM on every request.

**Using SystemPrompt (recommended):**

```php
public function instructions(): string
{
    return (string) new SystemPrompt(
        background: ["You are an AI Agent specialized in writing YouTube video summaries."],
        steps: [
            "Get the url of a YouTube video, or ask the user to provide one.",
            "Use the tools you have available to retrieve the transcription of the video.",
            "Write the summary.",
        ],
        output: [
            "Write a summary in a paragraph without using lists. Use just fluent text.",
            "After the summary add a list of three sentences as the three most important take away from the video.",
        ]
    );
}
```

- **background**: Role and macro tasks of the Agent.
- **steps**: How the Agent should behave; multiple steps improve consistency.
- **output**: Desired response format; be explicit.

**Simple string alternative:**

```php
public function instructions(): string
{
    return "You are an AI Agent specialized in writing YouTube video summaries.";
}
```

### Talking to the Agent

Input and output use `Message` classes. Send `UserMessage`, receive `AssistantMessage`.

```php
use NeuronAI\Chat\Messages\UserMessage;

$response = YouTubeAgent::make()->chat(
    new UserMessage("Who are you?")
);

echo $response->getContent();
```

### Fluent Agent Definition

You can define the agent inline with a fluent API instead of a dedicated class:

```php
use NeuronAI\Agent;
use NeuronAI\SystemPrompt;
use NeuronAI\Providers\Anthropic\Anthropic;
use NeuronAI\Chat\Messages\UserMessage;

$agent = Agent::make()
    ->setAiProvider(
        new Anthropic(
            key: 'ANTHROPIC_API_KEY',
            model: 'ANTHROPIC_MODEL',
        )
    )
    ->setInstructions(
        (string) new SystemPrompt(...)
    )
    ->addTool([...]);

$response = $agent->chat(new UserMessage(...));
```

### Monitoring (Inspector)

Set in `.env` to monitor Agent/LLM calls:

```
INSPECTOR_INGESTION_KEY=nwse877auxxxxxxxxxxxxxxxxxxxxxxxxxxxx
```

---

## 2. AI Provider

With Neuron you can switch LLM providers with one line; the Agent code stays the same. All providers implement `NeuronAI\Providers\AIProviderInterface`.

### Anthropic

```php
use NeuronAI\Providers\Anthropic\Anthropic;
use NeuronAI\Providers\HttpClientOptions;

return new Anthropic(
    key: 'ANTHROPIC_API_KEY',
    model: 'ANTHROPIC_MODEL',
    parameters: [],
    httpOptions: new HttpClientOptions(timeout: 30),
);
```

### OpenAI (Responses API — recommended)

```php
use NeuronAI\Providers\OpenAI\Responses\OpenAIResponses;

return new OpenAIResponses(
    key: 'OPENAI_API_KEY',
    model: 'OPENAI_MODEL',
    parameters: [],
    strict_response: false,
    httpOptions: new HttpClientOptions(timeout: 30),
);
```

### OpenAI (Completions API)

```php
use NeuronAI\Providers\OpenAI\OpenAI;

return new OpenAI(
    key: 'OPENAI_API_KEY',
    model: 'OPENAI_MODEL',
    parameters: [],
    strict_response: false,
    httpOptions: new HttpClientOptions(timeout: 30),
);
```

### Azure OpenAI

```php
use NeuronAI\Providers\AzureOpenAI;

return new AzureOpenAI(
    key: 'AZURE_API_KEY',
    endpoint: 'AZURE_ENDPOINT',
    model: 'OPENAI_MODEL',
    version: 'AZURE_API_VERSION'
);
```

### OpenAILike (e.g. Together, other OpenAI-compatible APIs)

```php
use NeuronAI\Providers\OpenAILike;

return new OpenAILike(
    baseUri: 'https://api.together.xyz/v1',
    key: 'API_KEY',
    model: 'MODEL',
    parameters: [],
    strict_response: false,
    httpOptions: new HttpClientOptions(timeout: 30),
);
```

### Ollama (local)

```php
use NeuronAI\Providers\Ollama\Ollama;

return new Ollama(
    url: 'OLLAMA_URL',
    model: 'OLLAMA_MODEL',
    parameters: [],
    httpOptions: new HttpClientOptions(timeout: 30),
);
```

### Gemini

```php
use NeuronAI\Providers\Gemini\Gemini;

return new Gemini(
    key: 'GEMINI_API_KEY',
    model: 'GEMINI_MODEL',
    parameters: [],
    httpOptions: new HttpClientOptions(timeout: 30),
);
```

### Gemini Vertex AI

Requires: `composer require google/auth`

```php
use NeuronAI\Providers\Gemini\GeminiVertex;

return new GeminiVertex(
    pathJsonCredentials: 'GOOGLE_FILE_CREDENTIALS_PATH',
    location: 'GOOGLE_LOCATION',
    projectId: 'GOOGLE_PROJECT_ID',
    model: 'GEMINI_MODEL',
    parameters: [],
    httpOptions: new HttpClientOptions(timeout: 30),
);
```

### Mistral

```php
use NeuronAI\Providers\Mistral\Mistral;

return new Mistral(
    key: 'MISTRAL_API_KEY',
    model: 'MISTRAL_MODEL',
    parameters: [],
    strict_response: false,
    httpOptions: new HttpClientOptions(timeout: 30),
);
```

### HuggingFace

```php
use NeuronAI\Providers\HuggingFace\HuggingFace;
use NeuronAI\Providers\HuggingFace\InferenceProvider;

return new HuggingFace(
    key: 'HF_ACCESS_TOKEN',
    model: 'mistralai/Mistral-7B-Instruct-v0.3',
    inferenceProvider: InferenceProvider::HF_INFERENCE,
    parameters: ['max_tokens' => 500, 'temperature' => 0.5]
);
```

### Deepseek

```php
use NeuronAI\Providers\Deepseek\Deepseek;

return new Deepseek(
    key: 'DEEPSEEK_API_KEY',
    model: 'DEEPSEEK_MODEL',
    parameters: [],
    strict_response: false,
    httpOptions: new HttpClientOptions(timeout: 30),
);
```

### Grok (X-AI)

```php
use NeuronAI\Providers\XAI\Grok;

return new Grok(
    key: 'GROK_API_KEY',
    model: 'grok-4',
    parameters: [],
    strict_response: false,
    httpOptions: new HttpClientOptions(timeout: 30),
);
```

### AWS Bedrock Runtime

Requires: `composer require aws/aws-sdk-php`

```php
use Aws\BedrockRuntime\BedrockRuntimeClient;
use NeuronAI\Providers\AWS\BedrockRuntime;

$client = new BedrockRuntimeClient([
    'version' => 'latest',
    'region' => 'us-east-1',
    'credentials' => [
        'key' => 'AWS_BEDROCK_KEY',
        'secret' => 'AWS_BEDROCK_SECRET',
    ],
]);

return new BedrockRuntime(
    client: $client,
    model: 'AWS_BEDROCK_MODEL',
    inferenceConfig: []
);
```

### Custom HTTP options

Use `NeuronAI\Providers\HttpClientOptions` for `timeout`, `connect_timeout`, and `headers`:

```php
use NeuronAI\Providers\HttpClientOptions;

return new Ollama(
    url: 'OLLAMA_URL',
    model: 'OLLAMA_MODEL',
    httpOptions: new HttpClientOptions(timeout: 30)
);
```

### Custom provider (AIProviderInterface)

Implement:

- `systemPrompt(?string $prompt): AIProviderInterface`
- `setTools(array $tools): AIProviderInterface`
- `messageMapper(): MessageMapperInterface`
- `chat(array $messages): Message`
- `stream(array|string $messages, callable $executeToolsCallback): \Generator`
- `structured(string $class, Message|array $messages, int $maxRetry = 1): mixed`

Use the trait `NeuronAI\Providers\HandleWithTools` and follow the template in the docs. Prefer submitting new providers via PR to the official repo.

---

## 3. Streaming

Use `stream()` instead of `chat()` to get a PHP generator and show response chunks in real time.

### Basic streaming

```php
use App\Neuron\MyAgent;
use NeuronAI\Chat\Messages\UserMessage;

$stream = MyAgent::make()->stream(
    new UserMessage('How are you?')
);

foreach ($stream as $text) {
    echo $text;
}
```

### Streaming with Tools

Tools/function calls are supported during streaming; they are handled in the middle of the stream.

```php
use NeuronAI\Tools\Tool;
use NeuronAI\Tools\ToolInterface;
// ToolCallMessage when chunk is a tool call

$stream = MyAgent::make()
    ->addTool(
        Tool::make(
            'get_server_configuration',
            'retrieve the server network configuration'
        )->addProperty(...)->setCallable(...)
    )
    ->stream(new UserMessage("What's the IP address of the server?"));

foreach ($stream as $chunk) {
    if ($chunk instanceof ToolCallMessage) {
        echo PHP_EOL . \array_reduce(
            $chunk->getTools(),
            fn(string $carry, ToolInterface $tool)
                => $carry .= '- Calling tool: ' . $tool->getName() . PHP_EOL,
            ''
        );
    } else {
        echo $chunk;
    }
}
```

---

## 4. Structured Output

Use when the Agent must return a fixed schema (e.g. for DB insert or downstream systems). Schema is defined by PHP classes and type hints; Neuron builds JSON schema for the LLM and validates/deserializes the response.

### Defining the output class

Use `NeuronAI\StructuredOutput\SchemaProperty` on properties. Prefer `description` and `required` for each property.

```php
<?php

namespace App\Neuron\Output;

use NeuronAI\StructuredOutput\SchemaProperty;

class Person
{
    #[SchemaProperty(description: 'The user name.', required: true)]
    public string $name;

    #[SchemaProperty(description: 'What the user love to eat.', required: false)]
    public string $preference;
}
```

### Calling structured()

```php
use NeuronAI\Chat\Messages\UserMessage;

$person = MyAgent::make()->structured(
    new UserMessage("I'm John and I like pizza!"),
    Person::class
);

echo $person->name . ' like ' . $person->preference; // John like pizza
```

### Default output class on the Agent

Encapsulate the default output class in the Agent; you still must call `structured()` to get strict output:

```php
class MyAgent extends Agent
{
    protected function getOutputClass(): string
    {
        return Person::class;
    }
}

$person = MyAgent::make()->structured(new UserMessage("I'm John and I like pizza"));
```

### Validation layer

Use validation attributes (e.g. `NotBlank`) in addition to `SchemaProperty`:

```php
use NeuronAI\StructuredOutput\Validation\Rules\NotBlank;

#[SchemaProperty(description: 'The user name.')]
#[NotBlank]
public string $name;
```

### Nested classes

Use another class as property type:

```php
#[SchemaProperty(description: 'The address to complete the delivery.', required: true)]
public Address $address;
```

Define `Address` with its own `SchemaProperty` and validation.

### Arrays

- Plain `array` is treated as array of strings unless specified otherwise.
- For array of objects: use `ArrayOf(SomeClass::class)` and docblock `@var \App\Neuron\Output\Tag[]` (or `array<\App\Neuron\Output\Tag>`).
- Multiple object types: `#[ArrayOf([TextBlock::class, TableBlock::class])]` with matching docblock.

### Max retries

By default Neuron retries once on validation errors. Customize:

```php
$person = MyAgent::make()->structured(
    messages: new UserMessage("I'm John and I like pizza!"),
    class: Person::class,
    maxRetries: 3
);
```

Use `maxRetries: 0` for a single attempt.

### Validation rules (summary)

- **NotBlank** — not blank; `allowNull` option.
- **Length** — string length: `min`, `max`, or `exactly`.
- **WordsCount** — word count: `exactly`, `min`, `max`.
- **Count** — array size: `min`, `max`, `exactly`.
- **EqualTo** / **NotEqualTo** — `reference` value.
- **GreaterThan** / **GreaterThanEqual** — numeric `reference`.
- **LowerThan** / **LowerThanEqual** — numeric `reference`.
- **OutOfRange** — number outside range; `strict` option.
- **IsFalse** / **IsTrue** — boolean.
- **IsNull** / **IsNotNull** — nullability.
- **Json** — valid JSON string.
- **Url** — valid URL.
- **Email** — valid email.
- **IpAddress** — valid IP.
- **ArrayOf(ClassName)** — array of given type(s); use docblock for deserialization.

All live under `NeuronAI\StructuredOutput\Validation\Rules\*`.

---

## 5. Error Handling

All Neuron exceptions extend `NeuronAI\Exceptions\NeuronException`. Catch at the appropriate level:

```php
try {
    // Agent / provider code...
} catch (NeuronAI\Exceptions\NeuronException $e) {
    // All agent-related exceptions
} catch (NeuronAI\Exceptions\ProviderException $e) {
    // AI providers and embedding providers
}
```

Use Inspector for alerts and observability.

---

## 6. Workflow — Multi Step

Workflows are event-driven: custom events are emitted by nodes and trigger other nodes. Define input/output per node via type hints.

### Custom events

Events can have any name/properties but must implement `Event`:

```php
namespace App\Neuron;

use NeuronAI\Workflow\Event;

class FirstEvent implements Event
{
    public function __construct(protected string $firstMsg) {}
}

class SecondEvent implements Event
{
    public function __construct(protected string $secondMsg) {}
}
```

### Creating nodes

**Unix:** `php vendor/bin/neuron make:node App\\Neuron\\InitialNode` (and NodeOne, NodeTwo).  
**Windows:** `php .\vendor\bin\neuron make:node App\Neuron\InitialNode` (etc.)

### Node implementation

Second argument is `WorkflowState` (or your custom state). Return type defines the next event.

```php
namespace App\Neuron;

use NeuronAI\Workflow\Node;
use NeuronAI\Workflow\StartEvent;
use NeuronAI\Workflow\StopEvent;
use NeuronAI\Workflow\WorkflowState;

class InitialNode extends Node
{
    public function __invoke(StartEvent $event, WorkflowState $state): FirstEvent
    {
        echo "\n- Handling StartEvent";
        return new FirstEvent("InitialNode complete");
    }
}

class NodeOne extends Node
{
    public function __invoke(FirstEvent $event, WorkflowState $state): SecondEvent
    {
        echo "\n- " . $event->firstMsg;
        return new SecondEvent("NodeOne complete");
    }
}

class NodeTwo extends Node
{
    public function __invoke(SecondEvent $event, WorkflowState $state): StopEvent
    {
        echo "\n- " . $event->secondMsg;
        echo "\n- NodeTwo complete";
        return new StopEvent();
    }
}
```

### Running the workflow

```php
use NeuronAI\Workflow\Workflow;

$handler = Workflow::make()
    ->addNodes([
        new InitialNode(),
        new NodeOne(),
        new NodeTwo(),
    ])
    ->start();

$handler->getResult();
```

---

## 7. Workflow — Loops & Branches

Control flow by returning different event types from `__invoke`. Declare **all** possible return types in the method signature so the workflow can build the execution chain.

### Loops

Return the same (or a previous) event to re-enter a node. Example: return `FirstEvent` to loop NodeOne, or `SecondEvent` to move on:

```php
class NodeOne extends Node
{
    public function __invoke(FirstEvent $event, WorkflowState $state): FirstEvent|SecondEvent
    {
        echo "\n- " . $event->firstMsg;

        if (rand(0, 1) === 1) {
            return new FirstEvent("Running a loop on NodeOne");
        }

        return new SecondEvent("NodeOne complete, move forward");
    }
}
```

You can also return `StartEvent` to jump back to the first node.

### Branches

Return different events to take different paths. Define separate events per branch (e.g. `BrancheA1Event`, `BrancheA2Event`, `BrancheB1Event`, `BrancheB2Event`), then in the initial node:

```php
public function __invoke(StartEvent $event, WorkflowState $state): BrancheA1Event|BrancheB1Event
{
    if (rand(0, 1) === 1) {
        return new BrancheA1Event(...);
    }
    return new BrancheB1Event(...);
}
```

Register all nodes (InitialNode, A1Node, A2Node, B1Node, B2Node, etc.) with `addNodes()`. You can combine branches and loops.

---

## 8. Workflow — Managing the State

- The workflow’s final value is the **state** instance.
- You can pass an **initial state** into `Workflow::make($initialState)`.
- Every node receives the state as the **second argument**; use it to read/write data across steps.

### Reading/writing state in nodes

```php
use NeuronAI\Workflow\WorkflowState;

public function __invoke(StartEvent $event, WorkflowState $state): StopEvent
{
    $state->set('message', 'Hello World!');
    return new StopEvent();
}
```

After run:

```php
$finalState = Workflow::make()
    ->addNode(new InitialNode())
    ->start()
    ->getReturn(); // or getResult() depending on API

echo $finalState->get('message');
```

### Initial state

```php
$workflow = Workflow::make(new WorkflowState(['query' => 'Hi!']))
    ->addNode(new InitialNode())
    ->addNode(...)
    ->addNode(...);

$finalState = $workflow->start()->getReturn();
echo $finalState->get('message');
```

### Typed state

Extend `WorkflowState` for type-safe access:

```php
use NeuronAI\Workflow\WorkflowState;

class CustomState extends WorkflowState
{
    protected User $user;

    public function setUser(User $user): CustomState
    {
        $this->user = $user;
        return $this;
    }

    public function getUser(): User
    {
        return $this->user;
    }
}
```

Use `CustomState` as the second parameter in nodes and pass it into `Workflow::make($state)`.

---

## 9. Workflow — Streaming

Stream progress (or agent output) by **yielding** events from nodes. Add `\Generator` to the return type of `__invoke`.

### Progress events

Define an event, e.g. `ProgressEvent` with `protected string $msg`. In nodes, yield it before returning the next transition event:

```php
public function __invoke(StartEvent $event, WorkflowState $state): \Generator|FirstEvent
{
    yield new ProgressEvent("Handling StartEvent");
    return new FirstEvent("InitialNode complete");
}
```

Consume with `streamEvents()`:

```php
$handler = Workflow::make()
    ->addNodes([new InitialNode(), new NodeOne(), new NodeTwo()])
    ->start();

foreach ($handler->streamEvents() as $event) {
    if ($event instanceof ProgressEvent) {
        echo "\n- " . $event->msg;
    }
}

$finalState = $handler->getResult();
echo "\n- " . $finalState->get('message');
```

### Streaming Agent output inside a node

Run the agent’s `stream()` and yield a custom event (e.g. `GenerationProgressEvent`) for each chunk:

```php
public function __invoke(StartEvent $event, WorkflowState $state): \Generator|FirstEvent
{
    $stream = Agent::make()->stream(new UserMessage($state->get('prompt')));

    foreach ($stream as $text) {
        yield new GenerationProgressEvent($text);
    }

    return new FirstEvent("InitialNode complete");
}
```

Listen for `GenerationProgressEvent` (and others) in `foreach ($handler->streamEvents() as $event) { ... }`.

---

## Checklist for implementation

- **Agents**: Extend `NeuronAI\Agent`, implement `provider()` and `instructions()`; use `UserMessage` / `AssistantMessage` for chat.
- **Providers**: Use one of the built-in providers or implement `AIProviderInterface`; use `HttpClientOptions` when needed.
- **Streaming**: Use `stream()` for agents; in workflows use `\Generator|Event` and `yield` + `streamEvents()`.
- **Structured output**: Define PHP classes with `SchemaProperty` (and validation rules); call `structured($message, ClassName::class)` or set `getOutputClass()`.
- **Errors**: Catch `NeuronException` and `ProviderException` where appropriate.
- **Workflows**: Define events implementing `Event`, nodes with `__invoke(Event, WorkflowState): Event`, attach with `addNodes()`, run with `start()` then `getResult()`/`getReturn()`; use state for cross-node data and custom state class for typing.
- **Monitoring**: Set `INSPECTOR_INGESTION_KEY` in `.env` when using Inspector.
